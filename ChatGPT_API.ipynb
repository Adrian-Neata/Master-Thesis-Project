{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRVsJ-XDqzdo",
        "outputId": "909c4454-e7b8-4e04-8801-255472709744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqXjJ7LSngXU",
        "outputId": "60dbebe1-d2be-49f4-ff36-72d86d551f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "openai.api_key = \"api_key\""
      ],
      "metadata": {
        "id": "hYR-Xy67neOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61543feFnY1q"
      },
      "outputs": [],
      "source": [
        "# !mkdir ~/.kaggle\n",
        "\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download ratthachat/writing-prompts\n",
        "# !unzip writing-prompts.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl-xXHm1neTh",
        "outputId": "ed965b16-6040-43de-8f7c-e1de487999c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading writing-prompts.zip to /content\n",
            " 97% 357M/370M [00:06<00:00, 91.9MB/s]\n",
            "100% 370M/370M [00:06<00:00, 56.0MB/s]\n",
            "Archive:  writing-prompts.zip\n",
            "  inflating: writingPrompts/README   \n",
            "  inflating: writingPrompts/test.wp_source  \n",
            "  inflating: writingPrompts/test.wp_target  \n",
            "  inflating: writingPrompts/train.wp_source  \n",
            "  inflating: writingPrompts/train.wp_target  \n",
            "  inflating: writingPrompts/valid.wp_source  \n",
            "  inflating: writingPrompts/valid.wp_target  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aux_valid_target = open('writingPrompts/train.wp_target', 'r')\n",
        "# aux_valid_source = open('writingPrompts/train.wp_source', 'r')\n",
        "\n",
        "# f = open(\"prompts.txt\", \"w\")\n",
        "# prompts = []\n",
        "# for i in range(10000):\n",
        "#   prompt = aux_valid_source.readline()\n",
        "#   story = aux_valid_target.readline()\n",
        "#   if not prompt:\n",
        "#     break\n",
        "\n",
        "#   if prompt != '' and story != '' and '[ WP ]' in prompt and len(prompt) > 40 and 'nsfw' not in prompt.lower() and 'make me' not in prompt.lower() and 'prompt ' not in prompt.lower() and 'username' not in prompt.lower() :\n",
        "#     prompts.append(prompt.replace('\\n', '<newline>'))\n",
        "#     f.write(prompt)\n",
        "# aux_valid_target.close()\n",
        "# aux_valid_source.close()\n",
        "# print(len(prompts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_N7gWEYn9cl",
        "outputId": "efb4317f-7aa1-41ee-86cd-5aad1fe826a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/drive/My Drive/prompts_edited.txt', 'r')\n",
        "prompts = []\n",
        "\n",
        "while True:\n",
        "  p = f.readline()\n",
        "  if not p:\n",
        "    break\n",
        "  prompts.append(p[:-1])\n",
        "\n",
        "print(len(prompts))\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mqy4KUJ2X51",
        "outputId": "b9081a15-1104-497b-8a35-3727b72df4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens_used = 6452155"
      ],
      "metadata": {
        "id": "IEKsLJhevhxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = open(\"/content/drive/My Drive/wp_target.txt\", \"a\")\n",
        "f2 = open(\"/content/drive/My Drive/wp_source.txt\", \"a\")\n",
        "\n",
        "for i in range(4850, 4950):\n",
        "  while True:\n",
        "    try:\n",
        "      response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "              {\"role\": \"user\", \"content\": \"Tell me a story about \" + prompts[i]},\n",
        "          ],\n",
        "        n=3\n",
        "      )\n",
        "      for j in range(3):\n",
        "        f1.write(response['choices'][j]['message']['content'].replace('\\n', '<newline>') + '\\n')\n",
        "        f2.write(prompts[i].replace('\\n', '<newline>') + '\\n')\n",
        "      total_tokens_used += response['usage']['total_tokens']\n",
        "      print(\"Iteration: \" + str(i) + \" Total Tokens: \" + str(total_tokens_used) + \" Cost: \" + str(total_tokens_used/1000 * 0.002) + '$')\n",
        "      break\n",
        "    except Exception as e:\n",
        "      # if chatGPT stopped working wait 100 seconds and try again\n",
        "      print(e)\n",
        "      time.sleep(100)\n",
        "f1.close()\n",
        "f2.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYaigTxOKE-Q",
        "outputId": "82c7700d-b4bd-4391-daa7-6b28c73d8293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 4810 Total Tokens: 6400398 Cost: 12.800796$\n",
            "Iteration: 4811 Total Tokens: 6401508 Cost: 12.803016$\n",
            "Iteration: 4812 Total Tokens: 6402940 Cost: 12.80588$\n",
            "Iteration: 4813 Total Tokens: 6404234 Cost: 12.808468000000001$\n",
            "Iteration: 4814 Total Tokens: 6405416 Cost: 12.810832000000001$\n",
            "Iteration: 4815 Total Tokens: 6406709 Cost: 12.813418$\n",
            "Iteration: 4816 Total Tokens: 6408014 Cost: 12.816028000000001$\n",
            "Iteration: 4817 Total Tokens: 6409260 Cost: 12.818520000000001$\n",
            "Iteration: 4818 Total Tokens: 6410251 Cost: 12.820502000000001$\n",
            "Iteration: 4819 Total Tokens: 6411610 Cost: 12.82322$\n",
            "Iteration: 4820 Total Tokens: 6413224 Cost: 12.826448000000001$\n",
            "Iteration: 4821 Total Tokens: 6414848 Cost: 12.829696$\n",
            "Iteration: 4822 Total Tokens: 6416833 Cost: 12.833666$\n",
            "Iteration: 4823 Total Tokens: 6418412 Cost: 12.836824$\n",
            "Iteration: 4824 Total Tokens: 6419045 Cost: 12.838090000000001$\n",
            "Iteration: 4825 Total Tokens: 6420483 Cost: 12.840966$\n",
            "Iteration: 4826 Total Tokens: 6422080 Cost: 12.84416$\n",
            "Iteration: 4827 Total Tokens: 6423864 Cost: 12.847728$\n",
            "Iteration: 4828 Total Tokens: 6425251 Cost: 12.850502$\n",
            "Iteration: 4829 Total Tokens: 6426537 Cost: 12.853074000000001$\n",
            "Iteration: 4830 Total Tokens: 6427891 Cost: 12.855782$\n",
            "Iteration: 4831 Total Tokens: 6429167 Cost: 12.858334000000001$\n",
            "Iteration: 4832 Total Tokens: 6430531 Cost: 12.861062$\n",
            "Iteration: 4833 Total Tokens: 6432040 Cost: 12.86408$\n",
            "Iteration: 4834 Total Tokens: 6433339 Cost: 12.866678$\n",
            "Iteration: 4835 Total Tokens: 6434148 Cost: 12.868296$\n",
            "Iteration: 4836 Total Tokens: 6435473 Cost: 12.870946$\n",
            "Iteration: 4837 Total Tokens: 6436801 Cost: 12.873602000000002$\n",
            "Iteration: 4838 Total Tokens: 6437808 Cost: 12.875616$\n",
            "Iteration: 4839 Total Tokens: 6438982 Cost: 12.877964$\n",
            "Iteration: 4840 Total Tokens: 6440290 Cost: 12.88058$\n",
            "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0f30a5936044cbeee5b4faa4e8fc82db in your message.)\n",
            "Iteration: 4841 Total Tokens: 6441948 Cost: 12.883896000000002$\n",
            "Iteration: 4842 Total Tokens: 6443242 Cost: 12.886484000000001$\n",
            "Iteration: 4843 Total Tokens: 6444442 Cost: 12.888884000000001$\n",
            "Iteration: 4844 Total Tokens: 6445554 Cost: 12.891108000000001$\n",
            "Iteration: 4845 Total Tokens: 6446747 Cost: 12.893494$\n",
            "Iteration: 4846 Total Tokens: 6447695 Cost: 12.895389999999999$\n",
            "Iteration: 4847 Total Tokens: 6449117 Cost: 12.898234$\n",
            "Iteration: 4848 Total Tokens: 6450855 Cost: 12.90171$\n",
            "Iteration: 4849 Total Tokens: 6452155 Cost: 12.90431$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "hJZ5xSIBrBOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1.close()\n",
        "f2.close()"
      ],
      "metadata": {
        "id": "I2tZsWzd05pF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}